# Python í†µí•© êµ¬í˜„ ê°€ì´ë“œ (íŒ€1 + íŒ€2)

**í”„ë¡œì íŠ¸**: EduMentor AI - Python ì„œë²„ (FastAPI)
**í¬íŠ¸**: 8000 (ë‹¨ì¼ ì„œë²„)
**êµ¬ì„±**: íŒ€1 QA ëª¨ë“ˆ + íŒ€2 ë¬¸ì œ ìƒì„± ëª¨ë“ˆ

---

## ğŸ“ í†µí•© í”„ë¡œì íŠ¸ êµ¬ì¡°

```
python-server/
â”œâ”€â”€ main.py                    # FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”œâ”€â”€ config.py                  # ê³µí†µ ì„¤ì •
â”œâ”€â”€ requirements.txt           # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env                       # í™˜ê²½ ë³€ìˆ˜
â”‚
â”œâ”€â”€ shared/                    # ê³µí†µ ëª¨ë“ˆ (íŒ€1+íŒ€2 ê³µìœ )
â”‚   â”œâ”€â”€ __init__.py            # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ chroma_client.py       # ChromaDB í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)
â”‚   â””â”€â”€ upstage_client.py      # Upstage API í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)
â”‚
â”œâ”€â”€ paper_qa/                  # íŒ€1: QA ì‹œìŠ¤í…œ (/qa)
â”‚   â”œâ”€â”€ __init__.py            # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ workflow.py            # LangGraph QA ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ api.py                 # QA API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ models.py              # Pydantic ëª¨ë¸
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py      # PDF íŒŒì‹± (Upstage Parse)
â”‚   â”‚   â””â”€â”€ ppt_parser.py      # PPT íŒŒì‹±
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ cache.py           # QA ì „ìš© ìºì‹± ë¡œì§
â”‚
â””â”€â”€ paper_problem/             # íŒ€2: ë¬¸ì œ ìƒì„± (/problems)
    â”œâ”€â”€ __init__.py            # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
    â”œâ”€â”€ workflow.py            # LangGraph ë¬¸ì œ ìƒì„± ì›Œí¬í”Œë¡œìš°
    â”œâ”€â”€ api.py                 # ë¬¸ì œ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸
    â”œâ”€â”€ models.py              # Pydantic ëª¨ë¸
    â”œâ”€â”€ generators/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ beginner.py        # ì´ˆê¸‰ ë¬¸ì œ ìƒì„±ê¸°
    â”‚   â”œâ”€â”€ intermediate.py    # ì¤‘ê¸‰ ë¬¸ì œ ìƒì„±ê¸°
    â”‚   â””â”€â”€ advanced.py        # ê³ ê¸‰ ë¬¸ì œ ìƒì„±ê¸°
    â”œâ”€â”€ validators/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ problem_validator.py  # ë¬¸ì œ ê²€ì¦ ë¡œì§
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ content_analyzer.py   # ë¬¸ì œìƒì„± ì „ìš© ë‚´ìš© ë¶„ì„
```

### ë””ë ‰í„°ë¦¬ ì—­í• 

| ë””ë ‰í„°ë¦¬ | ì—­í•  | ê³µìœ  ì—¬ë¶€ |
|---------|------|---------|
| **shared/** | ChromaDB, Upstage API ê³µí†µ í´ë¼ì´ì–¸íŠ¸ | íŒ€1+íŒ€2 ê³µìœ  |
| **paper_qa/utils/** | QA ì „ìš© ìºì‹± ë¡œì§ | íŒ€1 ì „ìš© |
| **paper_problem/utils/** | í•™ìŠµ ë‚´ìš© ë¶„ì„ ë¡œì§ | íŒ€2 ì „ìš© |

**ì¤‘ìš”**: `shared/`ì˜ `chroma_client.py`ì™€ `upstage_client.py`ëŠ” ë‘ íŒ€ì´ ê³µìœ í•©ë‹ˆë‹¤.

---

## 1. í”„ë¡œì íŠ¸ ì´ˆê¸° ì„¤ì •

### 1.1 ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# requirements.txt (Python 3.12.12 í˜¸í™˜)
# ìµœì¢… requirements.txt:

# LangChain & LangGraph
langchain>=0.3.7
langgraph>=0.2.45
langsmith>=0.1.140
langchain-community>=0.3.7
langchain-text-splitters>=0.3.2

# Upstage API
langchain-upstage>=0.1

# Vector DB
chromadb>=0.5.0

# FastAPI
fastapi>=0.115.0
uvicorn[standard]>=0.32.0
pydantic>=2.9.0
pydantic-settings>=2.6.0
python-multipart>=0.0.12

# ìœ í‹¸ë¦¬í‹°
python-dotenv>=1.0.0
aiohttp>=3.10.0
```

```bash
# ì„¤ì¹˜
pip install -r requirements.txt
```

### 1.2 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```python
# config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # Upstage API
    UPSTAGE_API_KEY: str

    # ChromaDB
    CHROMA_HOST: str = "localhost"
    CHROMA_PORT: int = 8001

    # File Storage
    UPLOAD_DIR: str = "./uploads"

    # Cache
    CACHE_SIZE: int = 100

    class Config:
        env_file = ".env"

settings = Settings()
```

```bash
# .env
# Upstage API
UPSTAGE_API_KEY=your_upstage_api_key

# ChromaDB
CHROMA_HOST=localhost
CHROMA_PORT=8001

# File Storage
UPLOAD_DIR=./data/materials

# Cache
CACHE_SIZE=100
```

**ì£¼ì˜**: Python ì„œë²„ëŠ” PostgreSQLì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PostgreSQL í™˜ê²½ë³€ìˆ˜ëŠ” Spring Bootì˜ `application.yml`ì—ë§Œ ì„¤ì •í•˜ì„¸ìš”.

---

## 2. ê³µí†µ ëª¨ë“ˆ (shared/)

### 2.1 __init__.py

```python
# shared/__init__.py
"""
ê³µí†µ ëª¨ë“ˆ íŒ¨í‚¤ì§€
ChromaDB í´ë¼ì´ì–¸íŠ¸ì™€ Upstage API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

from shared.chroma_client import chroma_client
from shared.upstage_client import upstage_client

__all__ = ['chroma_client', 'upstage_client']
```

### 2.2 ChromaDB í´ë¼ì´ì–¸íŠ¸

```python
# shared/chroma_client.py
import chromadb
from chromadb.config import Settings as ChromaSettings
from typing import List, Dict
from config import settings
import logging

logger = logging.getLogger(__name__)

class ChromaClient:
    """ChromaDB í´ë¼ì´ì–¸íŠ¸ (íŒ€1, íŒ€2 ê³µìœ )"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.client = chromadb.HttpClient(
            host=settings.CHROMA_HOST,
            port=settings.CHROMA_PORT,
            settings=ChromaSettings(
                anonymized_telemetry=False
            )
        )
        self._initialized = True
        logger.info("ChromaDB client initialized")

    def get_or_create_collection(self, name: str):
        """ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°"""
        return self.client.get_or_create_collection(
            name=name,
            metadata={"hnsw:space": "cosine"}
        )

    def add_documents(
        self,
        collection_name: str,
        documents: List[str],
        metadatas: List[Dict],
        ids: List[str],
        embeddings: List[List[float]] = None
    ):
        """ë¬¸ì„œ ì¶”ê°€"""
        collection = self.get_or_create_collection(collection_name)

        if embeddings:
            collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids,
                embeddings=embeddings
            )
        else:
            collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )

    def search(
        self,
        collection_name: str,
        query_texts: List[str] = None,
        query_embeddings: List[List[float]] = None,
        n_results: int = 3,
        filter_dict: Dict = None
    ):
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        collection = self.get_or_create_collection(collection_name)

        return collection.query(
            query_texts=query_texts,
            query_embeddings=query_embeddings,
            n_results=n_results,
            where=filter_dict
        )

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
chroma_client = ChromaClient()
```

### 2.3 Upstage í´ë¼ì´ì–¸íŠ¸

```python
# shared/upstage_client.py
from upstage import Upstage
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from config import settings
from typing import List
import asyncio
import logging

logger = logging.getLogger(__name__)

class UpstageClient:
    """Upstage API í´ë¼ì´ì–¸íŠ¸ (íŒ€1, íŒ€2 ê³µìœ )"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.client = Upstage(api_key=settings.UPSTAGE_API_KEY)
        self.embeddings = UpstageEmbeddings(
            api_key=settings.UPSTAGE_API_KEY,
            model="embedding-query"
        )
        self._initialized = True
        logger.info("Upstage client initialized")

    async def parse_pdf(self, file_path: str) -> dict:
        """PDF íŒŒì‹±"""
        result = await asyncio.to_thread(
            self.client.document_parse,
            file=file_path
        )
        return result

    async def embed_query(self, text: str) -> List[float]:
        """ì¿¼ë¦¬ ì„ë² ë”©"""
        return await self.embeddings.aembed_query(text)

    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì„ë² ë”©"""
        embeddings = UpstageEmbeddings(
            api_key=settings.UPSTAGE_API_KEY,
            model="embedding-passage"
        )
        return await embeddings.aembed_documents(texts)

    def get_chat_model(self, model: str = "solar-1-mini-chat", temperature: float = 0.3):
        """Chat ëª¨ë¸ ë°˜í™˜"""
        return ChatUpstage(
            api_key=settings.UPSTAGE_API_KEY,
            model=model,
            temperature=temperature
        )

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
upstage_client = UpstageClient()
```

---

## 3. íŒ€1: QA ì‹œìŠ¤í…œ

### 3.1 __init__.py

```python
# paper_qa/__init__.py
"""
íŒ€1: QA ì‹œìŠ¤í…œ ëª¨ë“ˆ
í•™ìŠµìë£Œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from paper_qa.api import router as qa_router
from paper_qa.workflow import upload_workflow, qa_workflow

__all__ = ['qa_router', 'upload_workflow', 'qa_workflow']
```

```python
# paper_qa/parsers/__init__.py
"""PDF/PPT íŒŒì„œ ëª¨ë“ˆ"""

from paper_qa.parsers.pdf_parser import pdf_parser
from paper_qa.parsers.ppt_parser import ppt_parser

__all__ = ['pdf_parser', 'ppt_parser']
```

```python
# paper_qa/utils/__init__.py
"""QA ì „ìš© ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ"""

from paper_qa.utils.cache import query_cache

__all__ = ['query_cache']
```

### 3.2 Pydantic ëª¨ë¸

```python
# paper_qa/models.py
from pydantic import BaseModel
from typing import List, Dict

class UploadResponse(BaseModel):
    material_id: int
    status: str
    blocks_count: int

class QARequest(BaseModel):
    material_id: int
    question: str

class QAResponse(BaseModel):
    answer: str
    sources: List[Dict]
    response_time_ms: int
```

### 3.3 PDF íŒŒì„œ

```python
# paper_qa/parsers/pdf_parser.py
from shared.upstage_client import upstage_client
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class PDFParser:
    async def parse(self, file_path: str) -> List[Dict]:
        """PDF íŒŒì‹±"""
        logger.info(f"Parsing PDF: {file_path}")

        parsed = await upstage_client.parse_pdf(file_path)
        content_blocks = []

        for element in parsed.get('elements', []):
            element_type = element.get('type')

            if element_type == 'text':
                content_blocks.append({
                    'type': 'text',
                    'content': element.get('content', ''),
                    'page': element.get('page', 1)
                })

        logger.info(f"Parsed {len(content_blocks)} blocks")
        return content_blocks

pdf_parser = PDFParser()
```

### 3.4 QA ì›Œí¬í”Œë¡œìš°

```python
# paper_qa/workflow.py
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List, Dict
from shared.chroma_client import chroma_client
from shared.upstage_client import upstage_client
from paper_qa.parsers.pdf_parser import pdf_parser
from langchain.schema import HumanMessage
import logging
import time

logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ State
class UploadState(TypedDict):
    material_id: int
    file_path: str
    file_type: str
    parsed_blocks: List[Dict]
    status: str

# QA State
class QAState(TypedDict):
    question: str
    material_id: int
    retrieved_docs: List[Dict]
    answer: str
    sources: List[Dict]

# ============ ì—…ë¡œë“œ ì›Œí¬í”Œë¡œìš° ============
async def parse_document_node(state: UploadState) -> dict:
    """ë¬¸ì„œ íŒŒì‹±"""
    file_path = state["file_path"]
    parsed_blocks = await pdf_parser.parse(file_path)
    return {"parsed_blocks": parsed_blocks}

async def embed_and_store_node(state: UploadState) -> dict:
    """ì„ë² ë”© ë° ChromaDB ì €ì¥"""
    material_id = state["material_id"]
    parsed_blocks = state["parsed_blocks"]

    texts = [block['content'] for block in parsed_blocks]
    embeddings = await upstage_client.embed_documents(texts)

    documents = []
    metadatas = []
    ids = []

    for idx, block in enumerate(parsed_blocks):
        documents.append(block['content'])
        metadatas.append({
            'material_id': material_id,
            'page': block['page'],
            'type': block['type']
        })
        ids.append(f"material_{material_id}_block_{idx}")

    chroma_client.add_documents(
        collection_name="learning_materials",
        documents=documents,
        metadatas=metadatas,
        ids=ids,
        embeddings=embeddings
    )

    return {"status": "completed"}

def create_upload_workflow():
    graph = StateGraph(UploadState)
    graph.add_node("parse", parse_document_node)
    graph.add_node("embed_store", embed_and_store_node)
    graph.add_edge(START, "parse")
    graph.add_edge("parse", "embed_store")
    graph.add_edge("embed_store", END)
    return graph.compile()

# ============ QA ì›Œí¬í”Œë¡œìš° ============
async def retrieve_node(state: QAState) -> dict:
    """ChromaDBì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ (0.2-0.3ì´ˆ ëª©í‘œ)"""
    start_time = time.time()

    question = state["question"]
    material_id = state["material_id"]

    # ì§ˆë¬¸ ì„ë² ë”©
    query_embedding = await upstage_client.embed_query(question)

    # ChromaDB ê²€ìƒ‰
    results = chroma_client.search(
        collection_name="learning_materials",
        query_embeddings=[query_embedding],
        n_results=3,
        filter_dict={"material_id": material_id}
    )

    retrieved_docs = []
    for i in range(len(results['documents'][0])):
        retrieved_docs.append({
            'content': results['documents'][0][i],
            'page': results['metadatas'][0][i]['page'],
            'distance': results['distances'][0][i]
        })

    elapsed = time.time() - start_time
    logger.info(f"âš¡ Retrieve time: {elapsed:.3f}s")

    return {"retrieved_docs": retrieved_docs}

async def generate_answer_node(state: QAState) -> dict:
    """ë‹µë³€ ìƒì„± (0.8-1.0ì´ˆ ëª©í‘œ)"""
    start_time = time.time()

    question = state["question"]
    retrieved_docs = state["retrieved_docs"]

    context = "\n\n---\n\n".join([
        f"[í˜ì´ì§€ {doc['page']}]\n{doc['content']}"
        for doc in retrieved_docs
    ])

    llm = upstage_client.get_chat_model(
        model="solar-1-mini-chat",
        temperature=0.3
    )

    prompt = f"""ë‹¹ì‹ ì€ í•™ìŠµìë£Œ ê¸°ë°˜ QA ë´‡ì…ë‹ˆë‹¤.

**í•™ìŠµìë£Œ ë‚´ìš©**:
{context}

**í•™ìƒ ì§ˆë¬¸**: {question}

**ë‹µë³€ ê·œì¹™**:
1. í•™ìŠµìë£Œì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš” (3-5ë¬¸ì¥)
3. ê´€ë ¨ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”

ë‹µë³€:"""

    response = await llm.ainvoke([HumanMessage(content=prompt)])
    answer = response.content

    sources = [
        {"page": doc["page"], "excerpt": doc["content"][:100] + "..."}
        for doc in retrieved_docs
    ]

    elapsed = time.time() - start_time
    logger.info(f"âš¡ Generate time: {elapsed:.3f}s")

    return {"answer": answer, "sources": sources}

def create_qa_workflow():
    graph = StateGraph(QAState)
    graph.add_node("retrieve", retrieve_node)
    graph.add_node("generate", generate_answer_node)
    graph.add_edge(START, "retrieve")
    graph.add_edge("retrieve", "generate")
    graph.add_edge("generate", END)
    return graph.compile()

# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤
upload_workflow = create_upload_workflow()
qa_workflow = create_qa_workflow()
```

### 3.5 QA API

```python
# paper_qa/api.py
from fastapi import APIRouter, UploadFile, HTTPException
from paper_qa.models import UploadResponse, QARequest, QAResponse
from paper_qa.workflow import upload_workflow, qa_workflow
from config import settings
import shutil
import os
import time

router = APIRouter()

@router.post("/upload", response_model=UploadResponse)
async def upload_material(file: UploadFile, material_id: int):
    """í•™ìŠµìë£Œ ì—…ë¡œë“œ ë° íŒŒì‹±"""

    file_ext = file.filename.split('.')[-1].lower()
    if file_ext not in ['pdf']:
        raise HTTPException(status_code=400, detail="Only PDF files are supported")

    os.makedirs(settings.UPLOAD_DIR, exist_ok=True)
    file_path = os.path.join(settings.UPLOAD_DIR, file.filename)

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    result = await upload_workflow.ainvoke({
        "material_id": material_id,
        "file_path": file_path,
        "file_type": "pdf"
    })

    return UploadResponse(
        material_id=material_id,
        status=result["status"],
        blocks_count=len(result["parsed_blocks"])
    )

@router.post("/ask", response_model=QAResponse)
async def ask_question(request: QARequest):
    """ì§ˆì˜ì‘ë‹µ (1-2ì´ˆ ëª©í‘œ)"""
    start_time = time.time()

    result = await qa_workflow.ainvoke({
        "question": request.question,
        "material_id": request.material_id
    })

    response_time = int((time.time() - start_time) * 1000)

    if response_time > 2000:
        print(f"âš ï¸ Slow response: {response_time}ms")
    else:
        print(f"âœ… Response time: {response_time}ms")

    return QAResponse(
        answer=result["answer"],
        sources=result["sources"],
        response_time_ms=response_time
    )
```

---

## 4. íŒ€2: ë¬¸ì œ ìƒì„±

### 4.1 __init__.py

```python
# paper_problem/__init__.py
"""
íŒ€2: ë¬¸ì œ ìƒì„± ëª¨ë“ˆ
ë‚œì´ë„ë³„ ì‹¤ìŠµ ë¬¸ì œ ìë™ ìƒì„± ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from paper_problem.api import router as problem_router
from paper_problem.workflow import problem_workflow

__all__ = ['problem_router', 'problem_workflow']
```

```python
# paper_problem/generators/__init__.py
"""ë¬¸ì œ ìƒì„±ê¸° ëª¨ë“ˆ"""

from paper_problem.generators.beginner import beginner_generator
from paper_problem.generators.intermediate import intermediate_generator
from paper_problem.generators.advanced import advanced_generator

__all__ = ['beginner_generator', 'intermediate_generator', 'advanced_generator']
```

```python
# paper_problem/validators/__init__.py
"""ë¬¸ì œ ê²€ì¦ ëª¨ë“ˆ"""

from paper_problem.validators.problem_validator import problem_validator

__all__ = ['problem_validator']
```

```python
# paper_problem/utils/__init__.py
"""ë¬¸ì œìƒì„± ì „ìš© ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ"""

from paper_problem.utils.content_analyzer import content_analyzer

__all__ = ['content_analyzer']
```

### 4.2 Pydantic ëª¨ë¸

```python
# paper_problem/models.py
from pydantic import BaseModel
from typing import List, Dict, Literal, Optional

class Problem(BaseModel):
    question: str
    answer: str
    hints: List[str]
    difficulty_score: int
    problem_type: Literal["CODING", "SHORT_ANSWER"]
    test_cases: Optional[List[Dict]] = []

class ProblemRequest(BaseModel):
    material_id: int
    difficulty: Literal["BEGINNER", "INTERMEDIATE", "ADVANCED"]
    problem_count: int = 3

class ProblemResponse(BaseModel):
    problems: List[Problem]
    difficulty: str
    generated_count: int
    rejected_count: int
```

### 4.3 Generator (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)

```python
# paper_problem/generators/beginner.py
from shared.upstage_client import upstage_client
from langchain.schema import HumanMessage
from paper_problem.models import Problem
from typing import List
import json
import logging

logger = logging.getLogger(__name__)

class BeginnerProblemGenerator:
    async def generate(self, context: str, count: int = 3) -> List[Problem]:
        """ì´ˆê¸‰ ë¬¸ì œ ìƒì„±"""

        llm = upstage_client.get_chat_model(temperature=0.7)

        prompt = f"""ë‹¤ìŒ í•™ìŠµ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ì´ˆê¸‰** ì‹¤ìŠµ ë¬¸ì œë¥¼ {count}ê°œ ìƒì„±í•˜ì„¸ìš”.

**í•™ìŠµ ë‚´ìš©**:
{context}

**ì´ˆê¸‰ ë¬¸ì œ ìš”êµ¬ì‚¬í•­**:
1. ê¸°ë³¸ ê°œë… ì´í•´ í™•ì¸
2. ë‹¨ìˆœí•œ ì½”ë“œ ì‘ì„± (5-10ì¤„)
3. ëª…í™•í•œ ì •ë‹µ

**ì¶œë ¥ í˜•ì‹** (JSON):
[
    {{
        "question": "ë¬¸ì œ ë‚´ìš©",
        "answer": "ì •ë‹µ ì½”ë“œ",
        "hints": ["íŒíŠ¸1", "íŒíŠ¸2"],
        "difficulty_score": 1-3,
        "problem_type": "CODING",
        "test_cases": [{{"input": "...", "expected": "..."}}]
    }}
]"""

        response = await llm.ainvoke([HumanMessage(content=prompt)])

        try:
            problems_data = json.loads(response.content)
            problems = [Problem(**p) for p in problems_data]
            logger.info(f"Generated {len(problems)} beginner problems")
            return problems
        except json.JSONDecodeError:
            logger.error("Failed to parse JSON")
            return []

beginner_generator = BeginnerProblemGenerator()
```

```python
# paper_problem/generators/intermediate.py ë° advanced.pyë„ ë™ì¼í•œ íŒ¨í„´
# (ì˜¨ë„ì™€ í”„ë¡¬í”„íŠ¸ë§Œ ë‹¤ë¦„)
```

### 4.4 ê²€ì¦ê¸°

```python
# paper_problem/validators/problem_validator.py
from paper_problem.models import Problem
from typing import List, Tuple
import logging

logger = logging.getLogger(__name__)

class ProblemValidator:
    def validate(self, problem: Problem, difficulty: str) -> Tuple[bool, str]:
        """ë¬¸ì œ ìœ íš¨ì„± ê²€ì¦"""

        if not problem.question or len(problem.question) < 50:
            return False, "Question too short"

        if not problem.answer or len(problem.answer) < 20:
            return False, "Answer too short"

        if len(problem.hints) < 2:
            return False, "Need at least 2 hints"

        difficulty_ranges = {
            "BEGINNER": (1, 3),
            "INTERMEDIATE": (4, 6),
            "ADVANCED": (7, 10)
        }

        min_score, max_score = difficulty_ranges[difficulty]
        if not (min_score <= problem.difficulty_score <= max_score):
            return False, f"Difficulty score must be {min_score}-{max_score}"

        return True, "Valid"

    def filter_valid_problems(
        self,
        problems: List[Problem],
        difficulty: str
    ) -> Tuple[List[Problem], List[str]]:
        """ìœ íš¨í•œ ë¬¸ì œë§Œ í•„í„°ë§"""

        valid_problems = []
        rejection_reasons = []

        for problem in problems:
            is_valid, reason = self.validate(problem, difficulty)
            if is_valid:
                valid_problems.append(problem)
            else:
                rejection_reasons.append(reason)

        return valid_problems, rejection_reasons

problem_validator = ProblemValidator()
```

### 4.5 ë¬¸ì œ ìƒì„± ì›Œí¬í”Œë¡œìš°

```python
# paper_problem/workflow.py
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List, Dict
from paper_problem.models import Problem
from shared.chroma_client import chroma_client
from paper_problem.generators.beginner import beginner_generator
from paper_problem.validators.problem_validator import problem_validator
import logging

logger = logging.getLogger(__name__)

class ProblemState(TypedDict):
    material_id: int
    difficulty: str
    problem_count: int
    learning_content: List[Dict]
    context: str
    generated_problems: List[Problem]
    validated_problems: List[Problem]
    rejection_reasons: List[str]

async def analyze_content_node(state: ProblemState) -> dict:
    """í•™ìŠµ ë‚´ìš© ì¶”ì¶œ"""
    material_id = state["material_id"]
    difficulty = state["difficulty"]

    results = chroma_client.search(
        collection_name="learning_materials",
        query_texts=["ê¸°ë³¸ ê°œë… ì˜ˆì œ"],
        n_results=5,
        filter_dict={"material_id": material_id}
    )

    learning_content = []
    for i in range(len(results['documents'][0])):
        learning_content.append({
            'content': results['documents'][0][i],
            'page': results['metadatas'][0][i]['page']
        })

    return {"learning_content": learning_content}

async def build_context_node(state: ProblemState) -> dict:
    """ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
    learning_content = state["learning_content"]

    context = "\n\n---\n\n".join([
        f"[í˜ì´ì§€ {c['page']}]\n{c['content']}"
        for c in learning_content
    ])

    return {"context": context}

async def generate_problems_node(state: ProblemState) -> dict:
    """ë¬¸ì œ ìƒì„±"""
    difficulty = state["difficulty"]
    context = state["context"]
    problem_count = state["problem_count"]

    if difficulty == "BEGINNER":
        problems = await beginner_generator.generate(context, problem_count)
    # elif INTERMEDIATE, ADVANCED...

    return {"generated_problems": problems}

async def validate_problems_node(state: ProblemState) -> dict:
    """ë¬¸ì œ ê²€ì¦"""
    problems = state["generated_problems"]
    difficulty = state["difficulty"]

    validated, rejected = problem_validator.filter_valid_problems(
        problems, difficulty
    )

    return {
        "validated_problems": validated,
        "rejection_reasons": rejected
    }

def create_problem_workflow():
    graph = StateGraph(ProblemState)

    graph.add_node("analyze", analyze_content_node)
    graph.add_node("build_context", build_context_node)
    graph.add_node("generate", generate_problems_node)
    graph.add_node("validate", validate_problems_node)

    graph.add_edge(START, "analyze")
    graph.add_edge("analyze", "build_context")
    graph.add_edge("build_context", "generate")
    graph.add_edge("generate", "validate")
    graph.add_edge("validate", END)

    return graph.compile()

problem_workflow = create_problem_workflow()
```

### 4.6 ë¬¸ì œ ìƒì„± API

```python
# paper_problem/api.py
from fastapi import APIRouter, HTTPException
from paper_problem.models import ProblemRequest, ProblemResponse
from paper_problem.workflow import problem_workflow

router = APIRouter()

@router.post("/generate", response_model=ProblemResponse)
async def generate_problems(request: ProblemRequest):
    """ë‚œì´ë„ë³„ ë¬¸ì œ ìƒì„±"""

    try:
        result = await problem_workflow.ainvoke({
            "material_id": request.material_id,
            "difficulty": request.difficulty,
            "problem_count": request.problem_count
        })

        validated_problems = result["validated_problems"]

        if not validated_problems:
            raise HTTPException(
                status_code=500,
                detail="Failed to generate valid problems"
            )

        return ProblemResponse(
            problems=validated_problems,
            difficulty=request.difficulty,
            generated_count=len(validated_problems),
            rejected_count=len(result["rejection_reasons"])
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

```python
# main.py
from fastapi import FastAPI
from paper_qa.api import router as qa_router
from paper_problem.api import router as problem_router
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

app = FastAPI(
    title="EduMentor AI Engine",
    description="QA ì‹œìŠ¤í…œ + ë¬¸ì œ ìƒì„± í†µí•© API",
    version="1.0.0"
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(qa_router, prefix="/qa", tags=["QA"])
app.include_router(problem_router, prefix="/problems", tags=["Problems"])

@app.get("/")
async def root():
    return {
        "service": "EduMentor AI Engine",
        "version": "1.0.0",
        "endpoints": {
            "qa": "/qa",
            "problems": "/problems",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "services": ["qa", "problems"]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 6. ì‹¤í–‰ ë°©ë²•

### 6.1 ë¡œì»¬ ê°œë°œ í™˜ê²½

```bash
# 1. ChromaDB ì‹œì‘
docker run -p 8001:8000 chromadb/chroma:latest

# 2. Python ì„œë²„ ì‹¤í–‰
cd python-server
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py
```

### 6.2 ì„œë²„ ì ‘ì†

- **API ë¬¸ì„œ**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

---

## 7. API ì‚¬ìš© ì˜ˆì‹œ

### 7.1 ìë£Œ ì—…ë¡œë“œ

```bash
curl -X POST http://localhost:8000/qa/upload \
  -F "file=@spring_guide.pdf" \
  -F "material_id=1"
```

### 7.2 ì§ˆë¬¸í•˜ê¸°

```bash
curl -X POST http://localhost:8000/qa/ask \
  -H "Content-Type: application/json" \
  -d '{
    "material_id": 1,
    "question": "JPA Entityë€ ë¬´ì—‡ì¸ê°€ìš”?"
  }'
```

### 7.3 ë¬¸ì œ ìƒì„±

```bash
curl -X POST http://localhost:8000/problems/generate \
  -H "Content-Type: application/json" \
  -d '{
    "material_id": 1,
    "difficulty": "BEGINNER",
    "problem_count": 3
  }'
```

---

## 8. í…ŒìŠ¤íŠ¸

### 8.1 ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸

```python
# test_integration.py
import requests

BASE_URL = "http://localhost:8000"

def test_full_flow():
    # 1. Health Check
    response = requests.get(f"{BASE_URL}/health")
    print(f"âœ… Health: {response.json()}")

    # 2. ìë£Œ ì—…ë¡œë“œ
    with open("test.pdf", "rb") as f:
        response = requests.post(
            f"{BASE_URL}/qa/upload",
            files={"file": f},
            data={"material_id": 1}
        )
    print(f"âœ… Upload: {response.json()}")

    # 3. QA í…ŒìŠ¤íŠ¸
    response = requests.post(
        f"{BASE_URL}/qa/ask",
        json={
            "material_id": 1,
            "question": "JPA Entityë€?"
        }
    )
    print(f"âœ… QA: {response.json()}")

    # 4. ë¬¸ì œ ìƒì„± í…ŒìŠ¤íŠ¸
    response = requests.post(
        f"{BASE_URL}/problems/generate",
        json={
            "material_id": 1,
            "difficulty": "BEGINNER",
            "problem_count": 3
        }
    )
    print(f"âœ… Problems: {response.json()}")

if __name__ == "__main__":
    test_full_flow()
```

---

## 9. Docker ë°°í¬

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/data

  python-server:
    build: ./python-server
    ports:
      - "8000:8000"
    environment:
      - UPSTAGE_API_KEY=${UPSTAGE_API_KEY}
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
    depends_on:
      - chromadb

volumes:
  chroma_data:
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê³µí†µ ëª¨ë“ˆ
- [ ] ChromaDB í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- [ ] Upstage í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- [ ] í™˜ê²½ ì„¤ì • íŒŒì¼

### íŒ€1 (QA)
- [ ] PDF íŒŒì„œ
- [ ] ì—…ë¡œë“œ ì›Œí¬í”Œë¡œìš°
- [ ] QA ì›Œí¬í”Œë¡œìš° (1-2ì´ˆ)
- [ ] API ì—”ë“œí¬ì¸íŠ¸

### íŒ€2 (ë¬¸ì œ ìƒì„±)
- [ ] Generator (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)
- [ ] ê²€ì¦ê¸°
- [ ] ë¬¸ì œ ìƒì„± ì›Œí¬í”Œë¡œìš°
- [ ] API ì—”ë“œí¬ì¸íŠ¸

### í†µí•©
- [ ] main.py êµ¬í˜„
- [ ] ë¼ìš°í„° ë“±ë¡
- [ ] í†µí•© í…ŒìŠ¤íŠ¸

---

**ì‘ì„±ì¼**: 2025-10-28
**ë‹¨ì¼ Python ì„œë²„**: Port 8000
